{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6c2d78",
   "metadata": {},
   "source": [
    "# Q&A Chatbot using LangChain + FAISS + Ollama\n",
    "\n",
    "This notebook implements a PDF‚Äëbased Question‚ÄëAnswering chatbot using:\n",
    "- **LangChain**\n",
    "- **FAISS vector store**\n",
    "- **Ollama LLM**\n",
    "- **Embeddings for semantic search**\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Project Structure\n",
    "- Load PDF documents  \n",
    "- Split and embed  \n",
    "- Store embeddings in FAISS  \n",
    "- Build a retrieval pipeline  \n",
    "- Generate answers using Ollama  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Setup\n",
    "Install dependencies listed in `requirements.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87593398",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain ollama openai faiss-cpu chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4cefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"phi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dcd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79759351",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "\n",
    "model = OllamaLLM(model=MODEL)\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't\n",
    "answer the question, reply \"say i don't know\"\n",
    "\n",
    "context: {context}\n",
    "\n",
    "question: {question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(r\"C:\\Users\\ASUS\\Desktop\\LLMs\\Q&A Chatbot\\jesc103.pdf\")\n",
    "\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4a36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    pages,\n",
    "    embedding = embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# chain.invoke({\"question\":\"Why do ionic compounds have high melting points?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(q, chain):\n",
    "    result = chain.invoke({'question': q})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    q = input('Your question: ')\n",
    "    if q.lower() in 'exit quit bye':\n",
    "        print('Bye bye!')\n",
    "        break\n",
    "    result = ask_question(q, chain)\n",
    "    print(result)\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995514a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
